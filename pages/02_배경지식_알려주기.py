import streamlit as st
from openai import OpenAI
from streamlit_chat import message
from dotenv import load_dotenv
import time

load_dotenv()


def clear_history():
    st.session_state["past"] = []
    st.session_state["generated"] = []


if "mesasges" not in st.session_state:
    st.session_state["messages"] = []
if "past" not in st.session_state:
    st.session_state["past"] = []
if "generated" not in st.session_state:
    st.session_state["generated"] = []

if "logined" not in st.session_state.keys() or not st.session_state["logined"]:
    st.error("ğŸš¨ ë¡œê·¸ì¸ì„ ë¨¼ì € í•´ì£¼ì„¸ìš”")
    st.stop()

if st.session_state["api_type"] == "open_ai":
    models = ["gpt-3.5-turbo-0613", "gpt-3.5-turbo-16k-0613"]

st.set_page_config(
    page_title="ì—­í• /ë°°ê²½ì§€ì‹ì„ ì£¼ê³  ëŒ€í™”í•´ë³´ê¸°",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={},
)


hide_streamlit_style = """
            <style>
            #MainMenu {visibility: hidden;}
            footer {visibility: hidden;}
            header {visibility: hidden;}
            </style>
            """


st.markdown(hide_streamlit_style, unsafe_allow_html=True)

explanation_0, explanation_1, explanation_2 = st.columns([0.07, 10, 0.07])
with explanation_1:
    st.title("ğŸ“ ChatGPTì— ì—­í• /ë°°ê²½ì§€ì‹ì„ ì•Œë ¤ì£¼ê¸° ")
    st.markdown(
        """
        <br>
        ì»´í“¨í„°ì—ê²Œ ì›í•˜ëŠ” ë‹µë³€ì„ í•˜ë„ë¡ ê¸¸ë“¤ì´ëŠ” ë°©ë²• ì¤‘ ê°€ì¥ ìœ ëª…í•œ ê²ƒì€ <b>ë°°ê²½ì§€ì‹ ë¶€ì—¬í•˜ê¸°</b> ì…ë‹ˆë‹¤.
        <br>
        í”íˆ <b>ì—­í•  ë¶€ì—¬ (Role-Playing)</b>ë¼ê³  ë¶ˆë¦¬ëŠ” ì´ ë°©ì‹ì€ ì–¸ì–´ ëª¨ë¸ì´ <b>ëŒ€í™”ì˜ ë§¥ë½</b>ì„ ìƒì„±í•˜ê²Œ í•©ë‹ˆë‹¤.
        <br>
        ë§¥ë½ì„ íŒŒì•…í•œë‹¤ëŠ”ê²Œ ë¬´ìŠ¨ ì˜ë¯¸ì¼ê¹Œìš”? ì‚¬ëŒì´ ëŒ€í™”í•˜ëŠ” ë°©ì‹ì„ ìƒê°í•´ë³´ê² ìŠµë‹ˆë‹¤.
        <br>
        ì ì ˆí•œ ëŒ€ë‹µì„ í•˜ê¸° ìœ„í•´ì„œ ëŒ€í™”ê°€ ì–´ëŠì •ë„ ì§„ì „ ë  í•„ìš”ê°€ ìˆì§€ìš”?
        <br>
        ê·¸ ë•Œ, ì‚¬ëŒì€ ëŒ€í™”ì˜ ë§¥ë½ì„ íŒŒì•…í•˜ëŠ” ê²ƒì„ í†µí•´ì„œ 'ì§€ê¸ˆ ê°€ì¥ ì ì ˆí•œ ì´ì•¼ê¸°'ë¥¼ í•˜ëŠ” ê²ƒ ì…ë‹ˆë‹¤.
        <br>
        ì¸ê³µì§€ëŠ¥ë„ ë˜‘ê°™ìŠµë‹ˆë‹¤! ì‚¬ëŒì²˜ëŸ¼ 'ì§€ê¸ˆ ê°€ì¥ ì ì ˆí•œ ëŒ€ë‹µ'ì„ í•˜ê¸° ìœ„í•´ì„œ ë§¥ë½ì„ íŒŒì•… í•  í•„ìš”ê°€ ìˆëŠ” ê²ƒ ì…ë‹ˆë‹¤.
        <br><br>
        """,
        unsafe_allow_html=True,
    )

st.sidebar.title("ì„¤ì •")

with st.sidebar:
    history_clear = st.button(label="ì´ˆê¸°í™”", on_click=clear_history)
    history_text_space = st.empty()

    if history_clear:
        with history_text_space:
            st.write("ëŒ€í™” ê¸°ë¡ì„ ì´ˆê¸°í™”í•˜ê³  ìˆì–´ìš” ğŸ˜‰")
            time.sleep(3)
            history_text_space.write("")

    st.write(
        """
        <font size=2>ëª¨ë¸ ì„¤ì •</font>
        """,
        unsafe_allow_html=True,
    )
    model_option = st.selectbox("Select Model", models)

    with st.expander(label="Max Words"):
        if model_option in ["gpt-3.5-turbo-0613"]:
            max_tokens = st.slider(
                "Max Words",
                min_value=5,
                max_value=4000,
                value=1000,
                step=1,
                label_visibility="hidden",
                help="ë‹µë³€ì˜ ìµœëŒ€ ê¸¸ì´ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.",
            )
        else:
            max_tokens = st.slider(
                "Max Words",
                min_value=5,
                max_value=16000,
                value=1000,
                step=1,
                label_visibility="hidden",
                help="ë‹µë³€ì˜ ìµœëŒ€ ê¸¸ì´ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.",
            )

    with st.expander(label="Temperature"):
        temperature = st.slider(
            "Temperature",
            min_value=0.0,
            max_value=2.0,
            value=0.5,
            step=0.1,
            label_visibility="hidden",
            help="ë‹µë³€ì˜ ë¬´ì‘ìœ„ì„±ì„ ê²°ì •í•©ë‹ˆë‹¤. ë‚®ì„ìˆ˜ë¡ ì •í˜•í™”ëœ ë‹µë³€ì„ ìƒì„±í•˜ê³ , ë†’ì„ìˆ˜ë¡ ì°½ì˜ì ì¸ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.",
        )
    with st.expander(label="Top P"):
        top_p = st.slider(
            "Top P",
            min_value=0.1,
            max_value=1.0,
            step=0.1,
            value=1.0,
            label_visibility="hidden",
            help="ë‹¨ì–´ë¥¼ ì„ íƒ í•  ë•Œ ììœ ë„ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. í´ìˆ˜ë¡ ë‹¤ì–‘í•œ ë‹¨ì–´ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.",
        )
    with st.expander(label="Presence Penalty"):
        presence_penalty = st.slider(
            "Presence Penalty",
            min_value=-2.0,
            max_value=2.0,
            value=0.0,
            step=0.1,
            label_visibility="hidden",
            help="ì§ˆë¬¸ì—ì„œ ë‚˜ì˜¨ ë‹¨ì–´ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ ë‹¨ì–´ë¥¼ ìƒì„± í•  ì§€ì— ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. ë†’ì„ìˆ˜ë¡ ìƒˆë¡œìš´ ì£¼ì œì— ëŒ€í•´ ì´ì•¼ê¸°í•©ë‹ˆë‹¤.",
        )
    with st.expander(label="Frequency Penalty"):
        frequency_penalty = st.slider(
            "Frequency Penalty",
            min_value=-2.0,
            max_value=2.0,
            value=0.0,
            step=0.1,
            label_visibility="hidden",
            help="ì§ˆë¬¸ì—ì„œ ë‚˜ì˜¨ ë‹¨ì–´ë“¤ì˜ ë¹ˆë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ ë‹¨ì–´ë¥¼ ìƒì„± í•  ì§€ì— ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. ë†’ì„ìˆ˜ë¡ ì§ˆë¬¸ ë¬¸ì¥ì— ì‚¬ìš©ëœ ë‹¨ì–´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.",
        )


ce, c1, ce, c2, c3 = st.columns([0.07, 3, 0.07, 6, 0.07])


with c1:
    with st.form("instruction_form", clear_on_submit=False):
        background_prompt = st.text_area(
            "ë°°ê²½ì§€ì‹/ì—­í•  ë¶€ì—¬í•˜ê¸°",
            height=250,
            key="background_prompt",
            disabled=False,
        )

        background_space = st.empty()
        b_0, b_1, b_2 = st.columns([10, 5, 4])

        with b_1:
            background_clear = st.form_submit_button(label="ì´ˆê¸°í™”")

        if background_clear:
            background_space.write(
                "<center> ì´ˆê¸°í™” ë˜ì—ˆìŠµë‹ˆë‹¤ ğŸ¤– </center>", 
                unsafe_allow_html=True
            )
            st.session_state["messages"] = []

        with b_2:
            submit = st.form_submit_button(label="ì…ë ¥")

        if submit:
            background_space.write(
                "<center>ì •ë³´ê°€ ì…ë ¥ë˜ì—ˆìŠµë‹ˆë‹¤ ğŸ¤–</center>",
                unsafe_allow_html=True
            )
            st.session_state["messages"].append(
                {"role": "system", "content": background_prompt}
            )

with c2:
    running = False
    with st.form("submit_form", clear_on_submit=True):
        user_input = st.text_area("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", "", key="input", disabled=running)
        p0, p1 = st.columns([20, 3])
        with p1:
            submit = st.form_submit_button(label="ì…ë ¥")

    loading_text_space = st.empty()

    if submit:
        with loading_text_space:
            st.write("<center>ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...â°</center>", unsafe_allow_html=True)

        for i in range(len(st.session_state["generated"])):
            st.session_state["messages"].append(
                {"role": "user", "content": st.session_state["past"][i]}
            )
            st.session_state["messages"].append(
                {"role": "assistant", "content": st.session_state["generated"][i]}
            )

        st.session_state["messages"].append({"role": "user", "content": user_input})

        running = True
        cli=OpenAI(api_key=st.session_state['api_key'])
        if st.session_state["api_type"] == "open_ai":
            res = client.chat.completions.create(
                max_tokens=max_tokens,
                temperature=temperature,
                top_p=top_p,
                presence_penalty=presence_penalty,
                frequency_penalty=frequency_penalty,
                stream=True,
                messages=st.session_state["messages"],
                model=model_option,
            )

        result = ""

        with st.empty():
            for x in res:
                if "content" in x.choices[0].delta.keys():
                    result += x.choices[0].delta.content

        st.session_state["past"].append(user_input)
        st.session_state["generated"].append(result)

    if st.session_state["generated"]:
        for i in range(len(st.session_state["generated"]) - 1, -1, -1):
            message(
                st.session_state["past"][i],
                avatar_style="fun-emoji",
                is_user=True,
                key=str(i) + "_user",
            )
            message(
                st.session_state["generated"][i],
                avatar_style="thumbs",
                is_user=False,
                key=str(i),
                seed=123,
            )

        loading_text_space.write("")
