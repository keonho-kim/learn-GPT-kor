import os
import streamlit as st
from dotenv import load_dotenv
import openai
from openai import OpenAI

load_dotenv()
st.set_page_config(
    page_title="ChatGPT ë¶„í•´í•˜ê¸°",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={},
)

client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])


hide_streamlit_style = """
            <style>
            #MainMenu {visibility: hidden;}
            footer {visibility: hidden;}
            header {visibility: hidden;}
            </style>
            """
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

st.header("ğŸ§Š ChatGPTì˜ ë‹µë³€ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ìš”ì†Œë“¤ ")

st.markdown(
    """
    <br>
    ChatGPTëŠ” ë‹¨ìˆœíˆ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ë‹¤ì–‘í•œ ê¸°ìˆ ì  ìˆ˜ì¹˜ë“¤ì— ì˜í–¥ì„ ë°›ìŠµë‹ˆë‹¤.\n
    ë‹¤ì–‘í•œ ìˆ˜ì¹˜ë“¤ì„ ì§ì ‘ ì¡°ì ˆí•´ë³´ë©´ì„œ ì‹¬ë„ê¹Šì€ ì´í•´ë¥¼ í•´ë´…ì‹œë‹¤.
    <br><br>
    """,
    unsafe_allow_html=True,
)

if "logined" not in st.session_state.keys() or not st.session_state["logined"]:
    st.error("ğŸš¨ ë¡œê·¸ì¸ì„ ë¨¼ì € í•´ì£¼ì„¸ìš”")
    st.stop()

if st.session_state["api_type"] == "open_ai":
    models = ["text-davinci-003", "gpt-3.5-turbo"]


with st.empty():
    with st.form(key="my_form"):
        ce, c1, ce, c2, c3 = st.columns([0.1, 3, 0.07, 6, 0.1])
        with c1:
            st.subheader("ì„¤ì •", anchor=None)
            model_option = st.selectbox("ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.", models)
            max_tokens = st.slider(
                "Maximum Length",
                min_value=5,
                max_value=4000,
                value=1000,
                step=1,
                label_visibility="visible",
                help="ë‹µë³€ì˜ ìµœëŒ€ ê¸¸ì´ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.",
            )

            temperature = st.slider(
                "Temperature",
                min_value=0.0,
                max_value=2.0,
                value=0.5,
                step=0.1,
                label_visibility="visible",
                help="ë‹µë³€ì˜ ë¬´ì‘ìœ„ì„±ì„ ê²°ì •í•©ë‹ˆë‹¤. ë‚®ì„ìˆ˜ë¡ ì •í˜•í™”ëœ ë‹µë³€ì„ ìƒì„±í•˜ê³ , ë†’ì„ìˆ˜ë¡ ì°½ì˜ì ì¸ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.",
            )
            top_p = st.slider(
                "Top P",
                min_value=0.1,
                max_value=1.0,
                step=0.1,
                value=1.0,
                label_visibility="visible",
                help="ë‹¨ì–´ë¥¼ ì„ íƒ í•  ë•Œ ììœ ë„ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. í´ìˆ˜ë¡ ë‹¤ì–‘í•œ ë‹¨ì–´ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.",
            )
            presence_penalty = st.slider(
                "Presence Penalty",
                min_value=-2.0,
                max_value=2.0,
                value=0.0,
                step=0.1,
                label_visibility="visible",
                help="ì§ˆë¬¸ì—ì„œ ë‚˜ì˜¨ ë‹¨ì–´ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ ë‹¨ì–´ë¥¼ ìƒì„± í•  ì§€ì— ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. ë†’ì„ìˆ˜ë¡ ìƒˆë¡œìš´ ì£¼ì œì— ëŒ€í•´ ì´ì•¼ê¸°í•©ë‹ˆë‹¤.",
            )
            frequency_penalty = st.slider(
                "Frequency Penalty",
                min_value=-2.0,
                max_value=2.0,
                value=0.0,
                step=0.1,
                label_visibility="visible",
                help="ì§ˆë¬¸ì—ì„œ ë‚˜ì˜¨ ë‹¨ì–´ë“¤ì˜ ë¹ˆë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ ë‹¨ì–´ë¥¼ ìƒì„± í•  ì§€ì— ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. ë†’ì„ìˆ˜ë¡ ì§ˆë¬¸ ë¬¸ì¥ì— ì‚¬ìš©ëœ ë‹¨ì–´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.",
            )

        with c2:
            runtime_parameters = {}
            text_prompt = st.text_area(
                label="a",
                disabled=False,
                height=450,
                max_chars=4000,
                label_visibility="hidden",
            )
            running = False
            p0, p1 = st.columns([20, 3])
            with p1:
                submitted = st.form_submit_button("ì…ë ¥", disabled=running)

            if not submitted:
                st.stop()

            running = True
            runtime_parameters["max_tokens"] = max_tokens
            runtime_parameters["temperature"] = temperature
            runtime_parameters["top_p"] = top_p
            runtime_parameters["presence_penalty"] = presence_penalty
            runtime_parameters["frequency_penalty"] = frequency_penalty
            runtime_parameters["stream"] = True

            if st.session_state["api_type"] == "azure":
                runtime_parameters["engine"] = st.session_state["model2deployment"][
                    model_option
                ]
            elif st.session_state["api_type"] == "open_ai":
                runtime_parameters["model"] = model_option

            if model_option in ["text-davinci-003"]:
                runtime_parameters["prompt"] = text_prompt
                res = client.completions.create(**runtime_parameters)
                result = ""
                with st.empty():
                    for x in res:
                        result += x.choices[0].text
                        st.markdown("#### ğŸ¤–:\n" + result)
                running = False

            else:
                messages = [
                    {"role": "system", "content": ""},
                    {"role": "user", "content": text_prompt},
                ]
                runtime_parameters["messages"] = messages
                res = client.chat.completions.create(**runtime_parameters)
                result = ""

                with st.empty():
                    for x in res:
                        if x.choices[0].delta.content:
                            result += x.choices[0].delta.content
                            st.markdown("#### ğŸ¤–:\n" + result)
                running = False
