import os
from openai import OpenAI
import streamlit as st
import time


# Define Functions 
def clear_history():
    st.session_state["messages"] = []

# LOGIN OPTION
if "OPENAI_API_KEY" not in os.environ:
    st.error("ğŸš¨ ë¡œê·¸ì¸ì„ ë¨¼ì € í•´ì£¼ì„¸ìš”")
    st.stop()


if "messages" not in st.session_state:
    st.session_state['messages'] = []

st.title("ìƒê°ì˜ ì—°ì‡„ ì‚¬ìš©í•˜ê¸°")

st.sidebar.title("ì„¤ì •")

with st.sidebar:

    history_clear = st.button(label="ì´ˆê¸°í™”", on_click=clear_history)
    history_text_space = st.empty()

    if history_clear:
        with history_text_space:
            st.write("ëŒ€í™” ê¸°ë¡ì„ ì´ˆê¸°í™”í•˜ê³  ìˆì–´ìš” ğŸ˜‰")
            time.sleep(3)
            history_text_space.write("")

    with st.expander("ì—­í•  ë¶€ì—¬í•˜ê¸°", expanded=True):
        with st.form("role_form", clear_on_submit=False):
            background_prompt = st.text_area(
                "ë°°ê²½ì§€ì‹/ì—­í• ",
                height=100,
                key="background_prompt",
                disabled=False,
                label_visibility='hidden'
            )

            background_space = st.empty()

            submit = st.form_submit_button(label="ì…ë ¥")

            if submit:
                background_space.write(
                    "<center>ì—­í• ì´ ë¶€ì—¬ë˜ì—ˆì–´ìš”.</center>",
                    unsafe_allow_html=True
                )
                st.session_state["messages"].append(
                    {"role": "system", "content": background_prompt}
                )
                
        
    with st.expander("ìƒê°ì˜ ì—°ì‡„", expanded=True):
        with st.form("cot_form", clear_on_submit=False):
            cot_prompt = st.text_area(
                "ìƒê°ì˜ ì—°ì‡„",
                height=100,
                key="cot_prompt",
                disabled=False,
                label_visibility='hidden'
            )

            background_space = st.empty()

            submit = st.form_submit_button(label="ì…ë ¥")

            if submit:
                background_space.write(
                    "<center>ìƒê°ì˜ ì—°ì‡„ê°€ ì…ë ¥ë˜ì—ˆì–´ìš”..</center>",
                    unsafe_allow_html=True
                )
                st.session_state["messages"].append(
                    {"role": "system", "content": cot_prompt}
                )
        
        
    models = ["gpt-3.5-turbo", "gpt-3.5-turbo-16k", 'gpt-4', 'gpt-4-1106-preview']
    model_option = st.selectbox("ëª¨ë¸ ì„ íƒ", models)

    with st.expander(label="Max Words"):
        max_tokens = st.slider(
            "Max Words",
            min_value=5,
            max_value= 4000,
            value=2000,
            step=1,
            label_visibility="hidden",
            help="ë‹µë³€ì˜ ìµœëŒ€ ê¸¸ì´ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.",
        )

    with st.expander(label="Temperature"):
        temperature = st.slider(
            "Temperature",
            min_value=0.0,
            max_value=2.0,
            value=0.5,
            step=0.1,
            label_visibility="hidden",
            help="ë‹µë³€ì˜ ë¬´ì‘ìœ„ì„±ì„ ê²°ì •í•©ë‹ˆë‹¤. ë‚®ì„ìˆ˜ë¡ ì •í˜•í™”ëœ ë‹µë³€ì„ ìƒì„±í•˜ê³ , ë†’ì„ìˆ˜ë¡ ì°½ì˜ì ì¸ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.",
        )
    with st.expander(label="Top P"):
        top_p = st.slider(
            "Top P",
            min_value=0.1,
            max_value=1.0,
            step=0.1,
            value=1.0,
            label_visibility="hidden",
            help="ë‹¨ì–´ë¥¼ ì„ íƒ í•  ë•Œ ììœ ë„ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. í´ìˆ˜ë¡ ë‹¤ì–‘í•œ ë‹¨ì–´ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.",
        )
    with st.expander(label="Presence Penalty"):
        presence_penalty = st.slider(
            "Presence Penalty",
            min_value=-2.0,
            max_value=2.0,
            value=0.0,
            step=0.1,
            label_visibility="hidden",
            help="ì§ˆë¬¸ì—ì„œ ë‚˜ì˜¨ ë‹¨ì–´ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ ë‹¨ì–´ë¥¼ ìƒì„± í•  ì§€ì— ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. ë†’ì„ìˆ˜ë¡ ìƒˆë¡œìš´ ì£¼ì œì— ëŒ€í•´ ì´ì•¼ê¸°í•©ë‹ˆë‹¤.",
        )
    with st.expander(label="Frequency Penalty"):
        frequency_penalty = st.slider(
            "Frequency Penalty",
            min_value=-2.0,
            max_value=2.0,
            value=0.0,
            step=0.1,
            label_visibility="hidden",
            help="ì§ˆë¬¸ì—ì„œ ë‚˜ì˜¨ ë‹¨ì–´ë“¤ì˜ ë¹ˆë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ ë‹¨ì–´ë¥¼ ìƒì„± í•  ì§€ì— ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. ë†’ì„ìˆ˜ë¡ ì§ˆë¬¸ ë¬¸ì¥ì— ì‚¬ìš©ëœ ë‹¨ì–´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.",
        )


cli = OpenAI()

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("ì´ì•¼ê¸°ë¥¼ í•´ë³¼ê¹Œìš”?"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        for response in cli.chat.completions.create(
            max_tokens=max_tokens,
            temperature=temperature,
            top_p=top_p,
            presence_penalty=presence_penalty,
            frequency_penalty=frequency_penalty,
            stream=True,
            messages=[
                {"role": m["role"], "content": m["content"]}
                for m in st.session_state.messages
                ],
            model=model_option,
        ):
            full_response += (response.choices[0].delta.content or "")
            message_placeholder.markdown(full_response + "â–Œ")
        message_placeholder.markdown(full_response)
    st.session_state.messages.append({"role": "assistant", "content": full_response})